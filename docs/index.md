# Med vLLM

Med vLLM is a specialized, lightweight variant of vLLM for medical NLP tasks. It includes adapters (BioBERT, ClinicalBERT), benchmarking tools, and a CLI for inference and validation.

## Quick links

- Benchmarks: [docs/benchmarks.md](benchmarks.md)
- CLI: [docs/CLI.md](CLI.md)
- GPU guide: [docs/GPU.md](GPU.md)
- NER Processor: [docs/ner_processor.md](ner_processor.md)
- Text Generator: [docs/text_generator.md](text_generator.md)
- Deployment Profiles: [docs/DEPLOYMENT_PROFILES.md](DEPLOYMENT_PROFILES.md)
- Testing: [docs/TESTING.md](TESTING.md)
- Validation Workflow: [docs/VALIDATION_WORKFLOW.md](VALIDATION_WORKFLOW.md)
- Optimization: [docs/OPTIMIZATION.md](OPTIMIZATION.md)
- Medical Models: [docs/medical_models.md](medical_models.md)
- UAT: [docs/UAT.md](UAT.md)
- Versions: [docs/VERSIONS.md](VERSIONS.md)

## Remaining items on TODO

- TPU validation: Must run on a real TPU VM.
- Specialized medical hardware: Needs the actual device (cannot be simulated meaningfully).
